The standard external-memory B-tree has branching factor B, and supports insertions, deletions, and searches in O(logb N).

We build a static complete binary tree with Θ(N) leaves, stored according to the van Emde Boas layout, and a packed-memory structure representing the elements. The structure maintains a fixed one-to-one correspondence (bidirectional pointers) between the cells in the packed-memory structure and the leaves in the tree. Some of these cells/leaves are occupied by  elements, while others are blank. 

Each internal node of the tree stores the maximum (nonblank) key of its two children, recursively. Thus, we can binary search through the tree, starting at the root, and at each step examining the key stored in the right child of the current node to decide whether to travel left or right. Because we stay entirely within the static search tree for a cost of O(logb N) memory transfers.

An insertion or deletion into the structure first searches for the location of the specified element (if it was not specified), and then issues a corresponding insert or delete operation to the packed-memory structure, which causes several nodes to move. Let K denote the number of moves, which is O(lg2 N) in the amortized sense. To maintain the one-to-one correspondence, the affected Θ(K) cells each update the key of its corresponding leaf. These key changes are propagated up the tree to all ancestors, eventually updating the maximum stored in the root. The propagation proceeds as a post-order traversal of the leaves and their ancestors, so that a node is updated only after its children have been updated. 

The claim is that this key propagation costs only O(K/B + logb N) memory transfers. We consider the coarsest level of detail at which each recursive subtree fits in a block, and hence stores between B and B nodes. The postorder traversal will proceed down the leftmost path of the tree to be updated. When it reaches a bottom recursive subtree, it will update all the elements in there; then it will go up to the recursive subtree above, and then return down to the next bottom recursive subtree. The nextto-bottom subtree and the bottom subtrees below have a total size of at least B, and assuming M ≥ 2B, these updates use blocks optimally. In this way, the total number of memory transfers to update the next-to-bottom and bottom levels is O(dK/Be) memory transfers. Above these levels, there are fewer than dK/Be elements whose values must be propagated up to dK/Be + lg N other nodes. We can afford an entire memory transfer for each of the dK/Be nodes. The remaining ≤ lg N nodes up to the root are traversed consecutively for a cost of O(logB N) memory transfers.

A streaming B-tree is a dictionary that efficiently implements insertions and range queries. We present two cache-oblivious streaming B-trees, the shuttle tree, and the cache-oblivious lookahead array (COLA).
  For block-transfer size B and on N elements, the shuttle tree implements searches in optimal O(log B+1N) transfers, range queries of L successive elements in optimal O(log sup(B+1) N +L/B) transfers, and insertions in O((log sup(B+1) N)/B^Θ(1/(log log B)^2)+(log^2N)/B) transfers, which is an asymptotic speedup over traditional B-trees if B ≥ (log N)^(1+c/log log log^2 N) for any constant c >1 [1].
  
  A COLA implements searches in O(log N) transfers, range queries in O(log N + L/B) transfers, and insertions in amortized O((log N)/B) transfers, matching the bounds for a (cache-aware) buffered repository tree. A partially deamortized COLA matches these bounds but reduces the worst-case insertion cost to O(log N) if memory size M = Ω(log N). We also present a cache-aware version of the COLA, the lookahead array, which achieves the same bounds as Brodal and Fagerberg's (cache-aware) Bε-tree [1].
  
  We compare our COLA implementation to a traditional B-tree. Our COLA implementation runs 790 times faster for random inser-tions, 3.1 times slower for insertions of sorted data, and 3.5 times slower for searches.
  
  
  The B-tree is the classic external-memory-dictionary data structure. The B-tree is typically analyzed in a two-level memory model, called the Disk Access Machine (DAM) model. The DAM model assumes an internal memory of size M organized into blocks of size B and an arbitrarily large external memory. The cost in the model is the number of transfers of blocks between the internal and external memory.
  
1. <a href="http://www.cs.cmu.edu/~jfineman/sbtree.pdf">Michael A. Bender, Martin Farach-Colton, Jeremy T. Fineman, Yonatan R. Fogel, Bradley C. Kuszmaul, Jelani Nelson Cache-Oblivious Streaming B-trees</a>

